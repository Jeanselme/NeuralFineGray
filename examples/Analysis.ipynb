{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file allows to analyze results obtained by running experiments_paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('../DeepSurvivalMachines/')\n",
    "from nfg import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to analyze other datasets result\n",
    "dataset = 'FRAMINGHAM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Results/' # Path where the data is saved\n",
    "x, t, e, covariates = datasets.load_dataset(dataset, competing = True, normalize = False) # Open the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_ipcw, brier_score, cumulative_dynamic_auc, integrated_brier_score\n",
    "\n",
    "### Utils\n",
    "def evaluate(survival, e = e, t = t, groups = None):\n",
    "    folds = survival.iloc[:, -1].values\n",
    "    survival = survival.iloc[:, :-1]\n",
    "    times = survival.columns.get_level_values(1).unique()\n",
    "    risk = 1 - survival\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # If multiple risk, compute cause specific metrics\n",
    "    for r in survival.columns.get_level_values(0).unique():\n",
    "        for fold in np.arange(5):\n",
    "            e_train, t_train = e[folds != fold], t[folds != fold]\n",
    "            e_test,  t_test  = e[folds == fold], t[folds == fold]\n",
    "            g_train, g_test = (None, None) if groups is None else (groups[folds != fold], groups[folds == fold])\n",
    "\n",
    "            et_train = np.array([(e_train[i] == int(r), t_train[i]) for i in range(len(e_train))], # For estimation censoring\n",
    "                            dtype = [('e', bool), ('t', float)])\n",
    "            et_test = np.array([(e_test[i] == int(r), t_test[i]) for i in range(len(e_test))], # For measure performance for given outcome\n",
    "                            dtype = [('e', bool), ('t', float)])\n",
    "            selection = (t_test < t_train.max()) | (e[folds == fold] != int(r))\n",
    "            \n",
    "            et_test, g_test = et_test[selection], None if groups is None else g_test[selection]\n",
    "            survival_fold = survival[folds == fold][r][selection]\n",
    "            risk_fold = risk[folds == fold][r][selection]\n",
    "\n",
    "            try:\n",
    "                brs = brier_score(et_train, et_test, survival_fold.values, times)[1]\n",
    "            except:\n",
    "                brs = [np.nan] * len(times)\n",
    "            # Concordance and ROC for each time\n",
    "            gcis, cis, rocs = [], [], []\n",
    "            res_group = {} if groups is None else {\"CIS_{}\".format(group): [] for group in groups.unique()}\n",
    "            for time in times:\n",
    "                try:\n",
    "                    gcis.append(concordance_index_ipcw(et_train, et_test, risk_fold[time])[0])\n",
    "                except:\n",
    "                    gcis.append(np.nan)\n",
    "                    \n",
    "                try:\n",
    "                    cis.append(concordance_index_ipcw(et_train, et_test, risk_fold[time], float(time))[0])\n",
    "                except:\n",
    "                    cis.append(np.nan)\n",
    "\n",
    "                try:\n",
    "                    rocs.append(cumulative_dynamic_auc(et_train, et_test, risk_fold[time], float(time))[0][0])\n",
    "                except:\n",
    "                    rocs.append(np.nan)\n",
    "\n",
    "                try:\n",
    "                    for group in groups.unique():\n",
    "                        res_group[\"CIS_{}\".format(group)].append(concordance_index_ipcw(et_train[g_train == group], et_test[g_test == group], risk_fold[time][g_test == group], float(time))[0])\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            res = {\"GCIS\": gcis, \"CIS\": cis, \"BRS\": brs, \"ROCS\": rocs}\n",
    "            if groups is not None:\n",
    "                res.update(res_group)\n",
    "            results[(r, fold)] = pd.DataFrame.from_dict(res, orient='index', columns = times)\n",
    "    results = pd.concat(results)\n",
    "    results.index.set_names(['Risk', 'Fold', 'Metric'], inplace = True)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To analyze group performance \n",
    "if dataset == \"FRAMINGHAM\":\n",
    "    groups = pd.DataFrame(x, columns = covariates).AGE\n",
    "    groups = pd.cut(groups, [0, 40, 50, 60, 100], labels=[\"<40\", \"40-50\", \"50-60\", \"60+\"])\n",
    "else:\n",
    "    groups = None\n",
    "groups.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file and compute performance\n",
    "predictions, clusters, results, likelihood = {}, {}, {}, {}\n",
    "for file_name in os.listdir(path):\n",
    "    if dataset in file_name and '.csv' in file_name: \n",
    "        model = file_name       \n",
    "        model = model[model.index('_') + 1: model.index('.')]\n",
    "\n",
    "        print(\"Opening :\", file_name, ' - ', model)\n",
    "        if 'finegray' in model:\n",
    "            # Reinitialize index\n",
    "            predictions[model] = pd.read_csv(path + file_name, header = [0], index_col = 0)\n",
    "            index = pd.DataFrame([[i, t] for i in ('1', '2') for t in predictions[model].columns[:3]] + [['Use', '']])\n",
    "            predictions[model].columns = pd.MultiIndex.from_frame(index)\n",
    "        else:\n",
    "            predictions[model] = pd.read_csv(path + file_name, header = [0, 1], index_col = 0)\n",
    "        results[model] = evaluate(predictions[model], groups = groups)\n",
    "\n",
    "        cluster_file = file_name[: file_name.index('.')] + '_clusters.pickle'\n",
    "        if os.path.isfile(path + cluster_file):\n",
    "            clusters[model] = pickle.load(open(path + cluster_file, 'rb'))\n",
    "# Rename\n",
    "# TODO: Add your method in the list for nicer display\n",
    "dict_name = {'nfg': 'NeuralFG', 'nfgcs': 'NeuralFG OvA', 'finegray': 'Fine Gray', 'dsm': 'DSM', 'dsmcs': 'DSM OvA', 'dh': 'DeepHit', 'dhcs': 'DeepHit OvA'} \n",
    "\n",
    "likelihood = pd.DataFrame.from_dict(likelihood, 'index').rename(dict_name)\n",
    "results = pd.concat(results).rename(dict_name)\n",
    "results.index.set_names('Model', 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = results.groupby(['Model', 'Risk', 'Metric']).apply(lambda x: pd.Series([\"{:.3f} ({:.2f})\".format(mean, std) for mean, std in zip(x.mean(), x.std())], index = x.columns.astype(float)))\n",
    "table = table.loc[table.index.get_level_values(2).isin(['CIS', 'BRS'])].unstack(level=-1).stack(level=0).unstack(level=-1).loc[:, ['CIS', 'BRS']]\n",
    "#table = table.loc[['NeuralFG', 'NeuralFG OvA', 'DSM', 'DeepHit', 'Fine Gray']]\n",
    "table = table.reorder_levels(['Risk', 'Model']).sort_index(level = 0, sort_remaining = False)\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = results.groupby(['Model', 'Risk', 'Metric']).apply(lambda x: pd.Series([\"{:.3f} ({:.2f})\".format(mean, std) for mean, std in zip(x.mean(), x.std())], index = x.columns.astype(float)))\n",
    "table = table.loc[table.index.get_level_values(2).str.contains('CIS_')].unstack(level=-1).stack(level=0).loc[['NeuralFG', 'NeuralFG OvA'], ['CIS_<40', 'CIS_40-50', 'CIS_50-60', 'CIS_60+']]\n",
    "#table = table.loc[['NeuralFG', 'NeuralFG OvA', 'DSM', 'DeepHit', 'Fine Gray']]\n",
    "table = table.reorder_levels(['Risk', 'Model', None]).sort_index(level = 0, sort_remaining = False)\n",
    "\n",
    "difference = (results.loc['NeuralFG'] - results.loc['NeuralFG OvA']).groupby(['Risk', 'Metric']).apply(lambda x: pd.Series([\"{:.3f} ({:.2f})\".format(mean, std) for mean, std in zip(x.mean(), x.std())], index = x.columns.astype(float)))\n",
    "difference = difference.loc[difference.index.get_level_values(1).str.contains('CIS_')].unstack(level=-1).stack(level=0).loc[:, ['CIS_<40', 'CIS_40-50', 'CIS_50-60', 'CIS_60+']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table.loc['2'].T.stack().reorder_levels([None, 'Metric']).sort_index(level = 0, sort_remaining = False)\n",
    "table['Difference'] = difference.loc['2'].stack()\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.concat({\"Age Group\": groups, \"Event\": pd.Series(e)}, 1).groupby(['Age Group', 'Event']).size().unstack().to_latex())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a54f3b3a447186e9a4a83057d2abe8df010acd7b8f131225203d307ef84eba48"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('Jupyter': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will apply Neural Fine Gray and Desurv on the FRAMINGHAM dataset and measure the execution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../DeepSurvivalMachines/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the FRAMINGHAM Dataset\n",
    "\n",
    "The package includes helper functions to load the dataset.\n",
    "\n",
    "X represents an np.array of features (covariates),\n",
    "T is the event/censoring times and,\n",
    "E is the censoring indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nfg import datasets\n",
    "x, t, e, columns = datasets.load_dataset('FRAMINGHAM', competing = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute horizons at which we evaluate the performance of Neural Fine Gray\n",
    "\n",
    "Survival predictions are issued at certain time horizons. Here we will evaluate the performance\n",
    "of NFG to issue predictions at the 25th, 50th and 75th event time quantile as is standard practice in Survival Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "np.random.seed(42)\n",
    "torch.random.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into train, test and validation sets\n",
    "\n",
    "We will train NSC on 80% of the Data (10 % of which is used for stopping criterion and 10% for model Selection) and report performance on the remaining 20% held out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def obtain_split(seed = 42):\n",
    "    x_train, x_test, t_train, t_test, e_train, e_test = train_test_split(x, t, e, test_size = 0.2, random_state = seed)\n",
    "    x_train, x_val, t_train, t_val, e_train, e_val = train_test_split(x_train, t_train, e_train, test_size = 0.2, random_state = seed)\n",
    "\n",
    "    minmax = lambda x: x / t_train.max() # Enforce to be inferior to 1\n",
    "    t_train_ddh = minmax(t_train).flatten()\n",
    "    t_test_ddh = minmax(t_test).flatten()\n",
    "    t_val_ddh = minmax(t_val).flatten()\n",
    "\n",
    "    return (x_train, t_train_ddh, e_train), (x_val, t_val_ddh, e_val), (x_test, t_test_ddh, e_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nfg import NeuralFineGray\n",
    "from desurv import DeSurv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = {'Mono': [], 'NFG': [], 'n=1': [], 'n=15': [], 'n=100': []}\n",
    "times = {'Mono': [], 'NFG': [], 'n=1': [], 'n=15': [], 'n=100': []}\n",
    "\n",
    "for i in range(100):\n",
    "    (x_train, t_train_ddh, e_train), (x_val, t_val_ddh, e_val), (x_test, t_test_ddh, e_test) = obtain_split(i)\n",
    "\n",
    "    for n in [1, 15, 100]:\n",
    "        np.random.seed(i)\n",
    "        torch.random.manual_seed(i)\n",
    "\n",
    "        start_time = time.process_time()\n",
    "        model = DeSurv(layers = [50, 50, 50], layers_surv = [50, 50, 50], n = n) \n",
    "        model.fit(x_train, t_train_ddh, e_train, n_iter = 1000, bs = 100, # Ensures that we train for n_iter iterations\n",
    "            lr = 1e-3, val_data = (x_val, t_val_ddh, e_val))\n",
    "        times['n={}'.format(n)].append(time.process_time() - start_time) # Time to converge\n",
    "        speed['n={}'.format(n)].append(model.speed) # Number iteration needed to converge\n",
    "\n",
    "    np.random.seed(i)\n",
    "    torch.random.manual_seed(i)\n",
    "    start_time = time.process_time()\n",
    "    model = NeuralFineGray(layers = [50], layers_surv = [50, 50], multihead = True) \n",
    "    model.fit(x_train, t_train_ddh, e_train, n_iter = 1000, bs = 100, # Ensures that we train for n_iter iterations\n",
    "        lr = 1e-3, val_data = (x_val, t_val_ddh, e_val))\n",
    "    times['NFG'].append(time.process_time() - start_time)\n",
    "    speed['NFG'].append(model.speed)\n",
    "\n",
    "    np.random.seed(i)\n",
    "    torch.random.manual_seed(i)\n",
    "    start_time = time.process_time()\n",
    "    model = NeuralFineGray(layers = [50], layers_surv = [50, 50], multihead = False) \n",
    "    model.fit(x_train, t_train_ddh, e_train, n_iter = 1000, bs = 100, # Ensures that we train for n_iter iterations\n",
    "        lr = 1e-3, val_data = (x_val, t_val_ddh, e_val))\n",
    "    times['Mono'].append(time.process_time() - start_time)\n",
    "    speed['Mono'].append(model.speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = pd.DataFrame.from_dict(speed)\n",
    "times = pd.DataFrame.from_dict(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = pd.Series([\"{:.2f} ({:.2f})\".format(mean, std) for mean, std in zip(speed.mean(), speed.std())], index = speed.columns)\n",
    "times = pd.Series([\"{:.2f} ({:.2f})\".format(mean, std) for mean, std in zip(times.mean(), times.std())], index = times.columns)\n",
    "speed, times"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('survival')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1b50223f39b64c0c24545f474e3e7d2d3b4b121fe045100fc03a3926bb649af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
